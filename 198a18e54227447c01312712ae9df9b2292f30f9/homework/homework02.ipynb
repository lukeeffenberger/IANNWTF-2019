{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "homework02.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SqSqqh1UXf7",
        "colab_type": "text"
      },
      "source": [
        "# Homework 02 - Perceptron and MLP\n",
        "\n",
        "This homework as two parts.\n",
        "\n",
        "1. Perceptron\n",
        "    * Implement perceptron in NumPy.\n",
        "    * Train it on AND, XOR gate.\n",
        "    * Visualize the training progress.\n",
        "\n",
        "\n",
        "2. MLP\n",
        "    * Answer basic questions about a simple MLP.\n",
        "    * Assign variable names to parts of the MLP.\n",
        "    * Perform a forward step by hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvu-_zcrUXf-",
        "colab_type": "text"
      },
      "source": [
        "## 1. Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EGr1KbyUXgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymK_UnadUXgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To make sure that you get the implementation right let us first have a look at the data structure.\n",
        "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "t_and = np.array([0,0,0,1])\n",
        "t_or = np.array([0,1,1,1])\n",
        "t_nand = np.array([1,1,1,0])\n",
        "t_nor = np.array([1,0,0,0])\n",
        "t_xor = np.array([0,1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jp2u-3tUXgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To make you familiar with classes we will implement the perceptron as a class.\n",
        "# Check https://docs.python.org/3/tutorial/classes.html if you need basic help with python classes.\n",
        "\n",
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, input_units):\n",
        "        self.input_units = input_units\n",
        "        ### YOUR CODE HERE ###\n",
        "        # 1. Initialize random weights and a random bias term. Check 'np.random.randn()'.\n",
        "        \n",
        "        # 2. Define the learning rate as 0.01.\n",
        "        \n",
        "        ######################\n",
        "        \n",
        "    def forward_step(self, data):\n",
        "        ### YOUR CODE HERE ###\n",
        "        # Perform a perceptron forward step.\n",
        "        # 1. Calculate the drive. Check the meaning of '@' in NumPy.\n",
        "        \n",
        "        # 2. Return a 1 or a 0, depending on whether the perceptron surpassed the threshold. \n",
        "        # You can use 'int(...)' to make an integer out of a boolean.\n",
        "        return        \n",
        "        ######################\n",
        "        \n",
        "    def training_step(self, data, label):\n",
        "        ### YOUR CODE HERE ###\n",
        "        # Perform a whole training step (including the forward step).\n",
        "        # 1. Forward step.\n",
        "        \n",
        "        # 2. Calculate the weight updates.\n",
        "        \n",
        "        # 3. Calculate the bias update \n",
        "        \n",
        "        # 4. Update weights and bias.\n",
        "        \n",
        "        #######################    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P-xgJlrUXgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's train the perceptron.\n",
        "\n",
        "# Choose which target you want to train on.\n",
        "t = t_and\n",
        "# Initialize a perceptron.\n",
        "perceptron = Perceptron(2)\n",
        "# Initialize lists to store steps and performance.\n",
        "steps = []\n",
        "accuracies = []\n",
        "\n",
        "# We train for 500 steps.\n",
        "for i in range(500):\n",
        "    steps.append(i)\n",
        "    \n",
        "    ### YOUR CODE HERE ###\n",
        "    # 1. Draw a random sample from x and the corresponding t. Check 'np.random.randint'\n",
        "    \n",
        "    # 2. Perform a training step.\n",
        "    \n",
        "    ######################\n",
        "    \n",
        "    # Calculate the performance over all four possible inputs.\n",
        "    accuracy_sum = 0\n",
        "    for k in range(4):\n",
        "        output = perceptron.forward_step(x[k])\n",
        "        accuracy_sum += int(output == t[k])\n",
        "    accuracy = accuracy_sum/4\n",
        "    accuracies.append(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nldgVxfBUXgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lastly let's plot the training progress.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(steps, accuracies)\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim([-0.1, 1.2])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhKno4ejUXgY",
        "colab_type": "text"
      },
      "source": [
        "## 2. MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZOodA6BUXgZ",
        "colab_type": "text"
      },
      "source": [
        "**Consider the following multi-layer perceptron:**\n",
        "\n",
        "<img src=\"https://github.com/lukeeffenberger/IANNWTF-2019/blob/master/198a18e54227447c01312712ae9df9b2292f30f9/homework/mlp.png?raw=1\" width=\"500\">\n",
        "\n",
        "**Please start by answering the follwing simple questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeWvOBvDUXgb",
        "colab_type": "text"
      },
      "source": [
        "**Q**: *How many hidden layers does this MLP have?*  \n",
        "**A**: \n",
        "\n",
        "**Q**: *How many layers does this MLP have?*    \n",
        "**A**: \n",
        "\n",
        "**Q**: *Out of how many perceptrons is this network built?*  \n",
        "**A**:\n",
        "\n",
        "**Q**: *How many input, hidden and output neurons does this network have?*    \n",
        "**A**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dUjmZ6zUXgd",
        "colab_type": "text"
      },
      "source": [
        "**Given an input** $\\vec{x} \\in \\mathbb{R}^2$ **the network function is defined as:**\n",
        "\n",
        "$$y = (\\vec{w}^{(2)}(W^{(1)} \\vec{x})^2)^2 \\hspace{325pt}$$\n",
        "\n",
        "**where**\n",
        "$$W^{(1)} = \\begin{pmatrix} 3 & 1 \\\\ -1 & 2 \\end{pmatrix}, \\vec{w}^{(2)} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}. \\hspace{325pt}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwCXnDCBUXgf",
        "colab_type": "text"
      },
      "source": [
        "**Q**: *What is the activation function* $\\sigma$ *in this MLP?*  \n",
        "**A**: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TtVNueZUXgi",
        "colab_type": "text"
      },
      "source": [
        "**Now given the input**\n",
        "\n",
        "$$\\vec{x} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} \\hspace{400pt}$$\n",
        "\n",
        "**compute the forward step. Given the input and the network function assign to each**  \n",
        "**number the correct variable name (e.g.** $x_1$**) and the correct value that this variable**  \n",
        "**has in this forward step.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ExZ4XFDUXgk",
        "colab_type": "text"
      },
      "source": [
        "| Number | Variable | Value |\n",
        "|:------:|:--------:|:-----:|\n",
        "|   1    |    $x_1$      |   2    |\n",
        "|   2    |          |       |\n",
        "|   3    |    $w_{11}^{(1)}$      |       |\n",
        "|   4    |          |       |\n",
        "|   5    |          |       |\n",
        "|   6    |          |       |\n",
        "|   7    |          |       |\n",
        "|   8    |          |       |\n",
        "|   9    |          |       |\n",
        "|  10    |          |       |\n",
        "|  11    |          |       |\n",
        "|  12    |          |       |\n",
        "|  13    |          |       |\n",
        "|  14    |          |       |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruRimh_IUXgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
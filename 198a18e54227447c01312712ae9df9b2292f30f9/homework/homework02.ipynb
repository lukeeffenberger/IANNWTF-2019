{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 02 - Perceptron and MLP\n",
    "\n",
    "This homework as two parts.\n",
    "\n",
    "1. Perceptron\n",
    "    * Implement perceptron in NumPy.\n",
    "    * Train it on AND, XOR gate.\n",
    "    * Visualize the training progress.\n",
    "\n",
    "\n",
    "2. MLP\n",
    "    * Answer basic questions about a simple MLP.\n",
    "    * Assign variable names to parts of the MLP.\n",
    "    * Perform a forward step by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that you get the implementation right let us first have a look at the data structure.\n",
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "t_and = np.array([0,0,0,1])\n",
    "t_or = np.array([0,1,1,1])\n",
    "t_nand = np.array([1,1,1,0])\n",
    "t_nor = np.array([1,0,0,0])\n",
    "t_xor = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make you familiar with classes we will implement the perceptron as a class.\n",
    "# Check https://docs.python.org/3/tutorial/classes.html if you need basic help with python classes.\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, input_units):\n",
    "        self.input_units = input_units\n",
    "        ### YOUR CODE HERE ###\n",
    "        # 1. Initialize random weights and a random bias term. Check 'np.random.randn()'.\n",
    "        \n",
    "        # 2. Define the learning rate as 0.01.\n",
    "        \n",
    "        ######################\n",
    "        \n",
    "    def forward_step(self, data):\n",
    "        ### YOUR CODE HERE ###\n",
    "        # Perform a perceptron forward step.\n",
    "        # 1. Calculate the drive. Check the meaning of '@' in NumPy.\n",
    "        \n",
    "        # 2. Return a 1 or a 0, depending on whether the perceptron surpassed the threshold. \n",
    "        # You can use 'int(...)' to make an integer out of a boolean.\n",
    "        return        \n",
    "        ######################\n",
    "        \n",
    "    def training_step(self, data, label):\n",
    "        ### YOUR CODE HERE ###\n",
    "        # Perform a whole training step (including the forward step).\n",
    "        # 1. Forward step.\n",
    "        \n",
    "        # 2. Calculate the weight updates.\n",
    "        \n",
    "        # 3. Calculate the bias update \n",
    "        \n",
    "        # 4. Update weights and bias.\n",
    "        \n",
    "        #######################    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train the perceptron.\n",
    "\n",
    "# Choose which target you want to train on.\n",
    "t = t_and\n",
    "# Initialize a perceptron.\n",
    "perceptron = Perceptron(2)\n",
    "# Initialize lists to store steps and performance.\n",
    "steps = []\n",
    "accuracies = []\n",
    "\n",
    "# We train for 500 steps.\n",
    "for i in range(500):\n",
    "    steps.append(i)\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    # 1. Draw a random sample from x and the corresponding t. Check 'np.random.randint'\n",
    "    \n",
    "    # 2. Perform a training step.\n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    # Calculate the performance over all four possible inputs.\n",
    "    accuracy_sum = 0\n",
    "    for k in range(4):\n",
    "        output = perceptron.forward_step(x[k])\n",
    "        accuracy_sum += int(output == t[k])\n",
    "    accuracy = accuracy_sum/4\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly let's plot the training progress.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(steps, accuracies)\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([-0.1, 1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider the following multi-layer perceptron:**\n",
    "<img src=\"mlp.png\" width=\"500\">\n",
    "**Please start by answering the follwing simple questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: *How many hidden layers does this MLP have?*  \n",
    "**A**: \n",
    "\n",
    "**Q**: *How many layers does this MLP have?*    \n",
    "**A**: \n",
    "\n",
    "**Q**: *Out of how many perceptrons is this network built?*  \n",
    "**A**:\n",
    "\n",
    "**Q**: *How many input, hidden and output neurons does this network have?*    \n",
    "**A**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given an input** $\\vec{x} \\in \\mathbb{R}^2$ **the network function is defined as:**\n",
    "\n",
    "$$y = (\\vec{w}^{(2)}(W^{(1)} \\vec{x})^2)^2 \\hspace{325pt}$$\n",
    "\n",
    "**where**\n",
    "$$W^{(1)} = \\begin{pmatrix} 3 & 1 \\\\ -1 & 2 \\end{pmatrix}, \\vec{w}^{(2)} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}. \\hspace{325pt}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: *What is the activation function* $\\sigma$ *in this MLP?*  \n",
    "**A**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now given the input**\n",
    "\n",
    "$$\\vec{x} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} \\hspace{400pt}$$\n",
    "\n",
    "**compute the forward step. Given the input and the network function assign to each**  \n",
    "**number the correct variable name (e.g.** $x_1$**) and the correct value that this variable**  \n",
    "**has in this forward step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Number | Variable | Value |\n",
    "|:------:|:--------:|:-----:|\n",
    "|   1    |    $x_1$      |   2    |\n",
    "|   2    |          |       |\n",
    "|   3    |    $w_{11}^{(1)}$      |       |\n",
    "|   4    |          |       |\n",
    "|   5    |          |       |\n",
    "|   6    |          |       |\n",
    "|   7    |          |       |\n",
    "|   8    |          |       |\n",
    "|   9    |          |       |\n",
    "|  10    |          |       |\n",
    "|  11    |          |       |\n",
    "|  12    |          |       |\n",
    "|  13    |          |       |\n",
    "|  14    |          |       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
